---
title: " **Análisis de Series de Tiempo de Homicidios en colombia** "
author: " *Andrés Barrios | Jesus Gallardo | Luis Tafur* "
date: " *`r Sys.Date()`*"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r, echo=FALSE, out.width="36%",out.height=="20%", fig.align = "center",warning=FALSE}
knitr::include_graphics("C:/Users/jrgal/OneDrive/Escritorio/Maestria/Series de Tiempo/Actividad 1/Imagen Analisis Homicidios.jpg")

```

## **Chapter 1 Descripción**
<div style= "text-align:justify">
La dinámica y evolución de los homicidios en Colombia constituye un fenómeno de gran relevancia que merece ser minuciosamente analizado y comprendido. Pues, el entendimiento de sus tendencias, patrones y factores resulta esencial para abordar la complejidad de este delito en el país. En este sentido, este análisis podría arrojar luz a aspectos cruciales como la variación estacional de los homicidios, los potenciales impactos de factores socioeconómicos y demográficos y/o la influencia de las políticas de seguridad implementadas en el territorio nacional.
<div/>

La base de datos proporcionada tiene un espacio temporal que data desde el **2010** hasta enero de **2024**.

**Fuente**: Dirección de Investigación Criminal e Interpol **(DIJIN) - Policía Nacional de Colombia**.

[GOV.CO_DatosAbiertos](https://www.datos.gov.co/Seguridad-y-Defensa/Homicidios-accidente-de-tr-nsito-Polic-a-Nacional/ha6j-pa2r/about_data)


```{r echo=FALSE,message=FALSE,warning=FALSE}
library(tidyverse) #Manipulación de data_set y gráficos ggplot
library(fpp2)
library(ggfortify)
library(forecast)
library(TTR)
library(lubridate)
library(tseries) #Prueba Dicker
library(stats) # Funciones ACF y PACF
library(plotly)
library(mice)
library(VIM)
library(htmlwidgets)
library(htmltools)
library(timsac)
library(changepoint)
library(fpp3)
library(prophet)
library(dplyr)


```


```{r echo=FALSE,message=FALSE,warning=FALSE}
#Cargue de data_set
data <- read_csv("C:/Users/jrgal/OneDrive/Escritorio/Maestria/Series de Tiempo/Actividad 2/Unidad 2 y 3/Serie_de_tiempo_avance_dia3/Serie_de_tiempo/Homicidios.csv")
```


## Análisis exploratorio

### *Dimensiones*

Se realiza la exploracion de las dimensiones de la base de datos evidenciando que esta cuenta con:
```{r echo=FALSE,message=FALSE,warning=FALSE}
#Dimensión
dimensiones=dim(data)
```
**Filas:** `r dimensiones[1]` **Columnas:** `r dimensiones[2]`

### *Tipo de variables*

Se debe corrigir el tipo de las columnas **FECHA HECHO** y **CANTIDAD**, dado a que éstas son de tipo **Date** y **Número**, luego de aplicar los cambios se observa:
```{r echo=FALSE,message=FALSE,warning=FALSE}

#Tipo de variables
data$`FECHA HECHO` <- as.Date(data$`FECHA HECHO`, format = "%d/%m/%Y")
data$CANTIDAD <- as.numeric(data$CANTIDAD)
Clase_Cant=class(data$CANTIDAD)
Clase_Fecha=class(data$`FECHA HECHO`)
```
- **CANTIDAD:** La variable es tipo `r Clase_Cant`
- **FECHA HECHO:** La variable es tipo `r Clase_Fecha`

### *Identificación de registros vacíos*
Se realiza la verificacion de valores nulos o vacios obteniendo los siguientes resultados:
```{r echo=FALSE,message=FALSE,warning=FALSE}
#Identificación de registros vacíos
as.table( apply(data, 2, function(x) sum(is.na(x))))
```
Clara mente se observa que no existen valos nulos o vacios en ninguna de las variables.


### *Identificación de registros vacíos*
Se realiza la verificacion de valores nulos o vacios obteniendo los siguientes resultados:
```{r echo=FALSE,message=FALSE,warning=FALSE}
par(mfrow=c(3,2))
md.pattern(data, rotate.names=TRUE)
```

Clara mente se observa que no existen valores nulos o vacios en ninguna de las variables.

### - *Resumen de Estadisticos*

A continuacion se muestra un resumen de los estadisticos basicos de nuestra variable **CANTIDAD**:
```{r echo=FALSE,message=FALSE,warning=FALSE}
#Estadísticas básicas
summary(data$CANTIDAD)
```


### - *Transformación del dataset*
A continuacion presentamos un resumen de los estadisticos de los homicidios totales de la serie de tiempo luego de realizar la transformacion de los datos:
 
```{r echo=FALSE,message=FALSE,warning=FALSE}
df <- data %>% select(`FECHA HECHO`, CANTIDAD) %>% 
  group_by(`FECHA HECHO`) %>% 
  summarise(HOMICIDIOS = sum(CANTIDAD)) %>% 
  rename(FECHA = `FECHA HECHO`) %>% 
  transmute(FECHA, HOMICIDIOS) %>% 
  mutate(Anio = year(FECHA),
         Mes = month(FECHA),
         AM = paste0(Anio, Mes)) %>% 
  select(AM, HOMICIDIOS) %>% 
  group_by(AM) %>% 
  summarise(Homicidios = sum(HOMICIDIOS))

df_ts <- ts(df$Homicidios, frequency = 12, start = 2010)

Inicio_TS=start(df_ts)

Fin_TS=end(df_ts)

Clase_TS=class(df_ts)

#Estadística Básica a la posterior transformación
Resumen_df_ts= df_ts

summary(Resumen_df_ts)
```
Dado a que es una serie de tiempo solo tendremos en cuenta la construcción de una base que contenga las variables **FECHA HECHO** y **CANTIDAD** para el analisis a realizar, de igualmanera se determinan los siguientes parametros:

- **Frecuencia de la serie:** Anual
- **Inicio de la Serie:** `r Inicio_TS`
- **Fin de la Serie:** `r Fin_TS`

adicionalmente se resaliza la verificacion de la clase de la serie de tiempo:

- **Calse de la serie:** `r Clase_TS`


### - *Garficos*
```{r echo=FALSE,message=FALSE,warning=FALSE, fig.align='center'}
# Graficar la serie de tiempo de homicidios en Colombia con plotly
plot_ly(x = time(df_ts), y = df_ts, type = "scatter", mode = "lines", line = list(color = "blue", width = 2)) %>%
  layout(title = list(text = "Homicidios por mes en Colombia (2010 - 2024)", x = 0.5),  # Ajustar la posición del título
         xaxis = list(title = "Meses"),
         yaxis = list(title = "Homicidios"),
         margin = list(l = 100, r = 100, t = 100, b = 100))  # Ajustar los márgenes para dejar espacio para la barra de herramientas
```

```{r echo=FALSE,message=FALSE,warning=FALSE, fig.align='center'}
boxplot(df_ts ~ cycle(df_ts), xlab = "Meses", ylab = "Homicidios",
        main = "Boxplot de los homicidios por meses")
```

Luego de analizar los resultados se evidencia que en el mes de abril hay mayor numero de homicidios, adicionalmente se evidencia que la media de los meses se encuentra entre los 400 y 500 homicidios.

En 7 meses se observan unos valores atipicos que superan los 1000 homicidios y uno en el que se presentaron menos de 200, seria de gran valor hacer un analisis detallado de estos datos con el objetivo de entender mejor la naturaleza de estos resultados.

```{r echo=FALSE,message=FALSE,warning=FALSE, fig.align='center'}
#Gráfica de rezagos
lag.plot(df_ts, 12, do.lines = F,main = "Grafica de Rezagos")

```

Para el caso de la grafica de rezagos se puede afirmar que no existe aleatoriedad, debido a que no se reflejan patrones identificables en los datos.


### - *Media Movil*
A continuacion se realiza el calculo de las medias moviles (SMA y EMA) de la serie de datos con el objetivo de obtener de forma mas clara el comportamiento de nuestra serie. 
```{r echo=FALSE,message=FALSE,warning=FALSE, fig.align='center'}
media_sim <- SMA(df_ts, n = 12)
media_exp <- EMA(df_ts, n = 12) # el parámetro n significa que se utilizará los ultimos 12 datos
Data_ts <- data.frame(fechas = seq(as.Date("2010-01-01"), by = "month",length.out = nrow(df)),
                      homicidios = df_ts)
```


### - *Gráfica de medias moviles exponencial vs simple*
```{r echo=FALSE,message=FALSE,warning=FALSE, fig.align='center'}
ggplot(Data_ts, aes(x = fechas, y = homicidios))+
  geom_line(aes(y = media_sim,color = "SMA"))+
  geom_line(aes(y = media_exp,color = "EMA"))+
  labs(x = " ", y = "Homicidios",
       title = "Media movil simple y exponencial de los Homicidios en Colombia 2010 a 2024")+
  theme_minimal()+
theme(legend.position = "top") +
  scale_color_manual(name = " ",
                     values = c("EMA" = "red", "SMA" = "blue"),
                     labels = c("EMA" = "Media Movil Exponencial", "SMA" = "Media Movil Simple"))+
  scale_x_date(date_breaks = "1 year", date_labels = "%Y")
```
Durante los últimos 13 años, los homicidios en Colombia han experimentado un aumento gradual.
Las medias móviles de 12 meses muestran que en 2010 había entre 230 y 240 asesinatos, comparados con 1000 a 850 asesinatos en los últimos meses de 2023 y enero de 2024, quintuplicando así las cifras de este fenómeno en el país. 
Se observa una tendencia a la baja al finalizar el primer semestre de cada año, seguido por un aumento durante los últimos meses, adicionalmente, se identifican dos períodos de fluctuaciones significativas: 

- Una baja notable al comienzo de la pandemia en 2020, dada la crisis sanitaria provocada por el COVID y la política de aislamiento social

- Un aumento sostenido en casi todo 2023, este comportamiento podria estar asociados a aumentos de bandas criminales y grupos armados como efecto de los cambios politicos que se generaron con el actual gobierno en materia de seguridad.

En cuanto a las líneas móviles exponenciales versus las simples, aunque no coinciden exactamente en su posición, sí lo hacen en cuanto a su tendencia, siendo la línea simple más suavizada que la exponencial.


```{r echo=FALSE,message=FALSE,warning=FALSE, fig.align='center'}
ggplot(Data_ts, aes(x = fechas, y = homicidios))+
  geom_line(color = "grey")+
  geom_line(aes(y = media_exp, color = "EMA"), linewidth = 0.5)+
  geom_line(aes(y = media_sim, color = "SMA"), linewidth = 0.5, alpha = 0.5)+
  labs(x = " ", y = "Homicidios",
       title = "Medias moviles vs cantidad de homicidios en Colombia 2010 a 2024")+
  theme_minimal()+
  theme(legend.position = "top") +
  scale_color_manual(name = " ",
                     values = c("EMA" = "red", "SMA" = "blue"),
                     labels = c("EMA" = "Media Movil Exponencial", "SMA" = "Media Movil Simple"))+
  scale_x_date(date_breaks = "1 year", date_labels = "%Y")
```
En congruencia con las medias móviles, se observa que la cantidad de homicidios no supera los 375 casos mensuales mensuales antes del 2020, sin embargo en el los periodos posteriores como en el 2023 se observa que se alcanzan valores tope hasta de 1000 muertes mesuales en el país a causa de los homicidios.

### - **Transformaciones básicas Series de Tiempo**
A continuacion realizaremos algunas transformaciones que nos permitiran detallar mucho mejor el analisis de nuestra serie de tiempo.

```{r echo=FALSE,message=FALSE,warning=FALSE, fig.align='center'}
fit_df <- decompose(df_ts, type='additive') # el componente 'additive' relaciona tendencia, estacionalidad y residuo

autoplot(fit_df, color = "aquamarine3") +
  labs(title = "Descomposicion de la serie de tiempo",                   
       x = "Tiempo",
       y = "Valor") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, size = 16),  # Centro el título y cambio el tamaño
  )

```
Acorde a la tendencia el comportamiento de los homicidios es lineal durante los años 2010 y 2020. Posteriormente, se vuelve creciente hasta finales del 2023.


### - *Identificación de Estacionalidad \nPrueba Dicker - Fuller*

```{r echo=FALSE,message=FALSE,warning=FALSE, fig.align='center'}

adf.test(df_ts)
```
Dado que el **p-value** es menor al nivel de significancia de **0.05** se acepta la hipotesis alternativa de que la serie sí es estacionaria

### - *Estacionalidad por año*
```{r echo=FALSE,message=FALSE,warning=FALSE, fig.align='center'}
ggseasonplot(df_ts)+
  theme_minimal()+
  labs(x = "Mes", title = "Estacionariedad de los homicidios por mes")
```

Se evidencian picos en la mayoría de los años principalmente en los meses de febrero, abril, junio y octubre, a excepción de 2023; a diferencia de los meses mayo, septiembre y noviembre, don de la cantidad de hpmicidios disminuye.


### - *Diferenciación*

Dado a que en los modelos de series de tiempo se requiere tener en cuenta la estacionariedad, para una mejor modelización y capacidad predictiva se procede a obtener las diferencias para hallarla. En otras palabras, se realiza para la estructuración del modelo a realizar.

**¿Cuántas diferencias se necesitan para hallar estacionariedad?**

```{r echo=FALSE,message=FALSE,warning=FALSE, fig.align='center'}
Diferencias=ndiffs(df_ts)

```

Despues de realizar el procedimiento de diferenciacion se llega a la conclusion que se solo se requieren `r Diferencias` diferencias para identificar la estacionariedad.

### - *Transformación para la variabilidad*
```{r echo=FALSE,message=FALSE,warning=FALSE, fig.align='center'}
x = log(df_ts) 
```

A continuacion, se aplica una transformacion logaritmica a la serie de tiempo, esto se realiza para cumplir con el supuesto de que la serie tiene variabilidad constante, para una mayor estabilidad e interpretación de datos.


### - *Aplicación de diferenciación*
```{r echo=FALSE,message=FALSE,warning=FALSE, fig.align='center'}
a_estacio = diff(x)
plot(a_estacio, xlab = "Anios", ylab = " ",
     main = "TS estacionariedad en los homicidios de Colombia \n2010 - 2024")
```

### - *Aplicación de función ACF*
```{r echo=FALSE,message=FALSE,warning=FALSE, fig.align='center'}
library(forecast)
acf(a_estacio, main = "Autocorrelacion")
```

El realizar la autocorrelacion nos permite identificar un comportamiento estacionario con respecto al tiempo en la serie de tiempo.

### - *Aplicación de función PACF*
```{r echo=FALSE,message=FALSE,warning=FALSE, fig.align='center'}
pacf(a_estacio, main = "Autocorrelacion parcial")
```

Al identificar la estructura autorregresiva en la serie, se tiene que, se necesitan 3 rezagos para predecir el valor actual de la serie.

### Aplicación de Holt-Winters Model.

Dada la evidencia de existencia de un valor medio, tendencia y estacionalidad en los datos; se permite la aplicación del modelo Holt-Winters; como modelo predictorio de largo y mediano plazo por medio de un triple suavizado exponencial al tener en cuenta los aspectos mencionados con anterioridad.

La primera decisión radica en elegir el tipo de patrón de estacionalidad, es decir, si este modelo debería ser representado por una estacionalidad aditiva o multiplicativa. Basándonos en la evidencia previamente encontrada, se observa una tendencia que aumenta o disminuye proporcionalmente con el promedio móvil de los datos, lo que sugiere que no permanece constante. Además, la amplitud de esta estacionalidad varía con el nivel encontrado. Por lo tanto, se decidió que el modelo a escoger será multiplicativo.

### Multiplicative

```{r echo=FALSE,message=FALSE,warning=FALSE, fig.align='center'}
Modelo <- HoltWinters(df_ts, seasonal = "multiplicative")

plot(Modelo, main = "Predicciones con modelo Holt-Winters", ylab = "Cantidad de Homicidios", xlab = "Tiempo (Anios)")
legend("bottomright", legend = c("Data", "Prediction"), col = c("black", "red"), lty = 1)

```

La gráfica nos brinda una visualización del comportamiento de las predicciones generadas por el modelo multiplicativo Holt-Winters. En un primer vistazo, podemos observar un ajuste cercano entre las predicciones y los datos base. Además, se aprecia una tendencia y estacionalidad similar entre ambas.

```{r echo=FALSE,message=FALSE,warning=FALSE, fig.align='center'}
# Se recuperan los valores alpha, beta, y gamma usados en el modelo
alpha <- Modelo$alpha
beta <- Modelo$beta
gamma <- Modelo$gamma
```

Los valores de los parámetro obtenidos son:
**Alpha:** `r alpha` \n
**Beta:** `r beta` \n
**Gamma:** `r gamma` \n

Al revisar los parámetros usados se puede apreciar que el modelo está dando más peso al parámetro **Alpha** que corresponde a la tendencia.

Para un mejor ajuste, se probará modificar los parametros **Beta**, **Gamma** y **Alpha** del modelo **holt-winters**, dado a que éstas se asocian respectivamente con tendencia, estacionalidad y nivel (**promedio móvil**).

**Alpha** es un número entre 0 y 1 que determina cuanto peso se le da a las observaciones más recientes al calcular la tendencia.

**Beta** es un número entre 0 y 1 que determina cuanto peso se le da a las observaciones más recientes en cuanto su estacionalidad.
      
**Gamma** es un número entre 0 y 1 que determina cuanto peso se le da a las observaciones más recientes en cuanto su nivel (promedio móvil).

```{r echo=FALSE,message=FALSE,warning=FALSE, fig.align='center'}
Modelo2 <- HoltWinters(df_ts, seasonal = "multiplicative", alpha = 0.7,
                       beta = 0, gamma = 0.9)
plot(Modelo2, main = "Predicciones con modelo Holt-Winters (Uso de parametros: Nivel)")
legend("bottomright", legend = c("Data", "Prediction"), col = c("black", "red"), lty = 1)
```

Al modificar dando más peso al parámetro **Gamma** correspondiente al Nivel, se puede apreciar como las estimaciones cambian en magnitud y los picos y valles no coinciden en igual proporción como en el modelo original.

```{r echo=FALSE,message=FALSE,warning=FALSE, fig.align='center'}
Modelo3 <- HoltWinters(df_ts, seasonal = "multiplicative", alpha = 0.7,
                       beta = 0.9, gamma = 0.1)
plot(Modelo3, main = "Predicciones con modelo Holt-Winters \n (Uso de parametros: Estacionalidad)")
legend("topleft", legend = c("Data", "Prediction"), col = c("black", "red"), lty = 1)

```

Al modificar dando más peso al parámetro **Beta** correspondiente a la Estacionalidad, se puede apreciar como las estimaciones del 2024 es muy diferente a los modelos anteriores, lo cual se explica al considerar lo ocurrido en el año 2023 como consecuencia de factores externos que sólo afectan en ese periodo de tiempo.

```{r echo=FALSE,message=FALSE,warning=FALSE, fig.align='center'}
Modelo4 <- HoltWinters(df_ts, seasonal = "multiplicative", alpha = 0.7,
                       beta = 0.1, gamma = 0.1)
plot(Modelo4, main = "Predicciones con modelo Holt-Winters (Uso de parametros: Estacionalidad)")
legend("topleft", legend = c("Data", "Prediction"), col = c("black", "red"), lty = 1)

```

```{r echo=FALSE,message=FALSE,warning=FALSE, fig.align='center'}
plot(fitted(Modelo), main = "Holt-winters Ajuste", xlab = "", ylab = "")

plot(fitted(Modelo4), main = "Holt-winters Ajuste", xlab = "", ylab = "")
```

El ajuste del modelo muestra una tendencia constante, un nivel que se aproxima a los datos observados y una estacionalidad periódica entre los años.

```{r echo=FALSE,message=FALSE,warning=FALSE, fig.align='center'}
prediction <- predict(Modelo, 11, prediction.interval = TRUE, level = 0.95)
plot(forecast(Modelo, h = 11, level = c(80,95)), main = "Predicciones en Colombia bajo el modelo Holt-Winters")

```

En los valores predichos bajo el modelo **Holt-winters**, se implementó la predicción de 11 meses posteriores a enero 2024 con intervalos de confianza del **80** y **95%**, observando unas barreras correspondientes a **1200** maximo y menos de **200** homicidios sin 0, por observación, el número estaría entre **180** a **150 homicidios**.

## - Forcast evaluation

```{r echo=FALSE,message=FALSE,warning=FALSE, fig.align='center'}
Modelo_evaluation <- forecast(Modelo, h = 11, level=c(80,95))

acf(Modelo_evaluation$residuals, lag.max=30, na.action=na.pass)
```

Realizando una autocorrelación a través de la función 'acf', se establecen unos rezagos de 30, haciendo alusión a la misma obsevación en el mes anterior, y dejando denotado no tener en cuenta los NA's en la operación.
     
Dado lo anterior, se observa que solo un error sobresale de la franja inferior de confianza, denotando la existencia de factores externos que tienen un grado elevado de significancia en la variabilidad de los datos pudiendo atribuirse a los cambios políticos del nuevo gobierno central o la crisis sanitaria.

## - Testeo de errores

La prueba Ljung-box evalua la hipotesis nula de que no hay autocorrelación en los datos hasta el rezago especificado, en este caso **30**.

```{r echo=FALSE,message=FALSE,warning=FALSE, fig.align='center'}
Box.test(Modelo_evaluation$residuals, lag=30, type="Ljung-Box")

```

Dado que **p-value** es mayor a **0.0**5 se acepta la hipotesis nula advertida en el parrafo anterior, lo que significa que en primera instacia hay una buena especificación del modelo, las predicciones son confiables y los residuos son aleatorios, lo que permite al modelo capturar adecuadamente la estructura de dependencia temporal de los datos.

```{r echo=FALSE,message=FALSE,warning=FALSE, fig.align='center'}
hist(Modelo_evaluation$residuals, main = "Residuos del modelo Holt-Winters")

```

Así las cosas, graficando los residuos del modelo, se tiene que gran parte de las observaciones se encuentran alrededor de **0**, lo que sugiere que el modelo no tiene un sesgo sistemático en sus predicciones; captura bien la estacionalidad y la tendencia de los datos; y explica en mayor parte la variabilidad de los datos.

## - Modelaje Box - Jenkins

La prueba dicker-fuller realizada en líneas de código anteriores, confirma estacionariedad en los datos con un **p-value** de **0.01**; se ajustó la variabilidad y se halló los rezagos correspondientes. De esta manera, con todas estas observaciones realizadas, este subcapitulo de modelaje se trabajará con el time series conformada de **'a_estacio'**

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}
# Hallando el modelo de ajuste

m_arima <- auto.arima(a_estacio)
m_arima
```

En respuesta a la **ARIMA(2,0,1)(0,0,2)[12]**; se tiene que el modelo mide una parte no estacional con los componentes **(2,0,1)** y estacional **(0,0,2)[12]**; esto, permitirá capturar patrones tanto de corto plazo como de largo plazo.De esta manera, la primera parte contiene **2** componentes autoregresivos. **0** de estacionariedad y **1** con media móvil; por su parte, la segunda contiene una media móvil de **2** y el período de evaluación de **12** meses refiriendosea que los datos se presentan de manera anual.
      
Por su parte los valores bajos de **AIC** (**Akaike Information Criterion**) de **-146.54** señala a complejidad del modelo, donde a menor valor mejor el modelo, **AICc** (**Corrected AIC**) de **-146.02** y **BIC** (**Bayesian Information Criterion**) de **-127.8** sugieren que el modelo se ajusta bien a los datos.

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}
# Hallando el punto de cambio de la media

p_change <- cpt.mean(a_estacio, method = "AMOC") # AMOC = "At most one change"
cpts(p_change)
```

retorna **numeric(0)**. Esto significa que no se detectaron puntos de cambio en la media de la serie temporal a_estacio utilizando el método 'AMOC'. En otras palabras, la serie temporal no muestra evidencia de un cambio significativo en la media en ningún punto.
      
La salida **numeric(0)** indica que la media de la serie temporal a_estacio es constante a lo largo del tiempo, al menos según el método **'AMOC'**.

## - Predicciones

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}
# Realizar predicciones a 11 pasos hacia adelante
predicciones <- forecast(m_arima, h = 11)

# Visualizar las predicciones
plot(predicciones, main = "Predicciones con el modelo ARIMA")
```

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}
residuales<-m_arima$residuals
qqnorm(residuales)
qqline(residuales)
shapiro.test(residuales)

```

Se puede observar que que hay residuos extremos tanto en la parte inferior como superior de la linea de ajuste. Adicionalmente en el test de Shapiro el valor **W: 0,856**, establece que los datos se alejan de un comportamiento normal, en lina con este resultado el **p-value: 1.487e-11** indica que existe suficiente evidencia estadistica para rechazar la hipotesis nula **Ho:Los datos provienen de una distribucion normal**.

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}
Box.test(residuales, type="Ljung-Box")

```

Dado que la p-value es mayor a 0.05 se acepta la hipotesis nula, lo que significa que en primera instacia hay una buena especificación del modelo, las predicciones son confiables y los residuos son aleatorios, lo que permite al modelo capturar adecuadamente la estructura de dependencia temporal de los datos.


# **Modelo Prophet**

Se realiza la aplicacion del modelo **Prophet**, debido a que el modelo solo reconoce las variables **ds** para unidad de tiempo y **y** para los valores de resultados se convierten las variables **fechas** y **homicidios** a este formato como se observa en la muestra a continuacion: 

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}
# La serie de tiempo debe ser estacionaria.

Data_ts <- Data_ts %>% rename(ds = fechas, y = homicidios) # El nombre para no modificar dataset original, Se debe renombrar las variables fechas y homicidios a ds y Y respectivamente, ya que la libreria solo conoce estos datos.

head(Data_ts)

```


```{r echo=FALSE, message=TRUE, warning=TRUE, fig.align='center'}

# Ajustar el modelo Prophet
modelo_prophet <- prophet(Data_ts,       # Se toma el nuevo dataset
                          yearly.seasonality = TRUE,
                          weekly.seasonality = FALSE, 
                          daily.seasonality = FALSE )

```

Dado a que los datos se encuentran por mes, el ajuste del modelo se realiza activando la estacionalidad anual y desactivando la diaria y semanal.





```{r echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}
# Crear un dataframe con las fechas futuras
futuro_prophet <- make_future_dataframe(modelo_prophet, periods = 11, freq = 'month')
```

El objetivo de prediccion para el modelo ajustado se establece para 11 periodos de la serie de tiempo, con una frecuencia mensual, lo que nos entregaria un resultado que abarca hasta diciembre 2024.

## Predicciones

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}
# Hacer las predicciones
forecast_prophet <- predict(modelo_prophet, futuro_prophet)
```

### - Visualizacion del Modelo

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}
# Visualizar los resultados
plot(modelo_prophet, forecast_prophet)
```

- Los puntos negros representan medidas reales de la serie de tiempo \n
- La linea azul el pronóstico de Prophet el cual muestra un ajuste significativo a los datos reales \n
- La banda azul representa el intervalo de incertidumbre, sin embargo este se muestra bastante conservador \n

El el grafico se puede observar el comportamiento durante el periodo de pandemia y la variación creciente del 2023 por fuera de las bandas predichas por el modelo, este comportamiento se muestra atipico en comparacion con el historico, lo que podria ser relevante analizar teniendo en cuenta la importancia de este indicador para la seguridad publica.

### - Componentes del Modelo
A continuacion se presentan los componentes de modelo **prophet** en los que se observa la tendencia y los residuos, permitiendo identificar el comportamiento del modelo hasta la prediccion.

Para el caso de la tendencia, es claro que la prediccion presenta un comportamiento ascendente para el año **2024**.

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}
prophet_plot_components(modelo_prophet, forecast_prophet)


```

La grafica de residuales de la prediccion muestran, que a finales de septiembre los homicidios en el país tienden a la baja; adicionalmente, los meses de julio y enero son donde este indicador sufre un incremento significativo en comparacion con el resto de los meses.
      

### - Comparación entre modelos

Se reversan las transformaciones en el modelo ARIMA para que todos las predicciones estén en la misma escala

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}
# Comparación entre modelos

# Se generan predicciones para el modelo ARIMA 
# se genera un modelo nuevo con los datos sin trasnformar
modelo_arima <- auto.arima(df_ts)
arima_forecasts <- forecast(modelo_arima)
```

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}
# Se generan predicciones para Prophet 
prophet_forecasts <- predict(modelo_prophet)
```

### - Estimacion de Métricas de precisión

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}
# Se estiman las métricas de precisión
# Se crea una función para estimar las métricas en todos los modelos 
compute_accuracy <- function(actual, forecast) {
  tibble(
    ME = mean(forecast - actual),
    RMSE = sqrt(mean((forecast - actual)^2)),
    MAE = mean(abs(forecast - actual)),
    MPE = mean((forecast - actual) / actual) * 100,
    MAPE = mean(abs((forecast - actual) / actual)) * 100,
    MASE = mean(abs(forecast - actual)) / mean(abs(diff(actual))),
    RMSSE = sqrt(mean((forecast - actual)^2)) / sqrt(mean(diff(actual)^2)),
    ACF1 = acf(forecast - actual, plot = FALSE)$acf[2]
  )
}
```


### - Valores Originales

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}
actual_values <-tail(Data_ts$y, n = 12)

actual_values
```

### - Estimacion de Metricas de Modelo

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}
# Se estiman las métricas para cada modelo
hw_accuracy <- compute_accuracy(actual_values, tail(Modelo$fitted, n = 12))
arima_accuracy <- compute_accuracy(actual_values, tail(arima_forecasts$fitted, n = 12))
prophet_accuracy <- compute_accuracy(actual_values, tail(prophet_forecasts$yhat, n = 12))
```

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}
# Se combinan los resultados en una sola tabla
accuracy_table <- bind_rows(
  tibble(Model = "Holt-Winters", hw_accuracy),
  tibble(Model = "ARIMA", arima_accuracy),
  tibble(Model = "Prophet", prophet_accuracy)
)

# Se imprime la tabla
print(accuracy_table)
```

De acuerdo a los resultados obtenidos, ell modelo ARIMA fue el modelo que obtuvo los mejores resultados en todas las métricas a excepción del MPE.






